{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["#This is only relevant if tomsup was installed from the github folder\n","#Move up to the correct folder\n","import os\n","os.chdir('..')\n","#And import the tomsup library\n","import tomsup as ts\n","\n","#Get the competitive penny game payoff matrix\n","penny = ts.PayoffMatrix(\"penny_competitive\")"]},{"source":["# On Initial Internal States and how to change Them\n","The simulated ToM agents in the tomsup package use agnostic beliefs about their opponent's level probabilities $\\lambda$ and choice probabilities $\\mu$, while parameter estimation means $\\mu^{\\theta}$ are set to 1. All variances $\\Sigma^{\\theta}$ and $\\Sigma$ for parameter and choice probability estimation, respectively, are also set to 1. Gradients for all parameters are 0 on the first trial, which means that no parameter estimates and variances are updated during the first trial. The tomsup package uses the same parameter values to the ones used in the VBA toolbox (Daunizeau et al., 2014) to enable comparison, but other settings are possible.\n","\n","While you can give initial states directly to `ts.TOM()` using the priors. It can be problematic to get the correct input format, we instead suggest you initialize the model with the defaults and then change the internal states to match your desired belief:"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'opponent_states': {0: {'opponent_states': {},\n","   'own_states': {'p_op_mean0': 0,\n","    'p_op_var0': 0,\n","    'p_self': nan,\n","    'p_op': nan}}},\n"," 'own_states': {'p_k': array([1.]),\n","  'p_op_mean': array([0]),\n","  'param_mean': array([[0., 0., 0.]]),\n","  'param_var': array([[0., 0., 0.]]),\n","  'gradient': array([[0., 0., 1.]]),\n","  'p_self': nan,\n","  'p_op': nan}}"]},"metadata":{},"execution_count":2}],"source":["tom_1 = ts.TOM(level=1)\n","init_states = tom_1.get_internal_states()\n","init_states"]},{"source":["For instance, a variable which one might wish to change is the estimation of it's opponent sophistication level when playing against humans. This is more likely to be 1 as opposed to 0. This it the variable `priors[\"own_states\"][\"p_k\"]` which is set to `[0.5, 0.5]` by default, i.e. agnostic. A more reasonable estimate for humans would favor the sophistication level 1. We can change it as follows:\n"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["init_states[\"own_states\"][\"p_k\"] = [0.3, 0.7]\n","tom_1.set_internal_states(init_states)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["opponent_states\n|   0-ToM\n|   |   opponent_states\n|   |   own_states\n|   |   |   p_op_mean0:  0\n|   |   |   p_op_var0:   0\n|   |   |   p_self:      nan\n|   |   |   p_op:        nan\nown_states\n|   p_k:         [0.3, 0.7]\n|   p_op_mean:   [0]\n|   param_mean:  [[0.0, 0.0, 0.0]]\n|   param_var:   [[0.0, 0.0, 0.0]]\n|   gradient:    [[0.0, 0.0, 0.999999997998081]]\n|   p_self:      nan\n|   p_op:        nan\n"]}],"source":["# print the changed states\n","tom_1.print_internal()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3},"version":"3.8.5-final"},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3,"kernelspec":{"name":"python37564bitea838f35b129458e9787f325adb7b1c3","display_name":"Python 3.7.5 64-bit","language":"python"}},"nbformat":4,"nbformat_minor":2}
{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["#This is only relevant if tomsup was installed from the github folder\n","#Move up to the correct folder\n","import os\n","os.chdir('..')\n","#And import the tomsup library\n","import tomsup as ts\n","\n","#Get the competitive penny game payoff matrix\n","penny = ts.PayoffMatrix(\"penny_competitive\")"]},{"source":["# On Initial Internal States and how to change Them\n","The simulated ToM agents in the tomsup package use agnostic beliefs about their opponent's level probabilities $\\lambda$ and choice probabilities $\\mu$, while parameter estimation means $\\mu^{\\theta}$ are set to 1. All variances $\\Sigma^{\\theta}$ and $\\Sigma$ for parameter and choice probability estimation, respectively, are also set to 1. Gradients for all parameters are 0 on the first trial, which means that no parameter estimates and variances are updated during the first trial. The tomsup package uses the same parameter values to the ones used in the VBA toolbox (Daunizeau et al., 2014) to enable comparison, but other settings are possible.\n","\n","While you can give initial states directly to `ts.TOM()` using the priors. It can be problematic to get the correct input format, we instead suggest you initialize the model with the defaults and then change the internal states to match your desired belief:"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'opponent_states': {0: {'opponent_states': {},\n","   'own_states': {'p_op_mean0': 0,\n","    'p_op_var0': 0,\n","    'p_self': nan,\n","    'p_op': nan}}},\n"," 'own_states': {'p_k': array([1.]),\n","  'p_op_mean': array([0]),\n","  'param_mean': array([[0., 0., 0.]]),\n","  'param_var': array([[0., 0., 0.]]),\n","  'gradient': array([[0., 0., 1.]]),\n","  'p_self': nan,\n","  'p_op': nan}}"]},"metadata":{},"execution_count":2}],"source":["tom_1 = ts.TOM(level=1)\n","init_states = tom_1.get_internal_states()\n","init_states"]},{"source":["For instance, a variable which one might wish to change is the estimation of it's opponent sophistication level when playing against humans. This is more likely to be 1 as opposed to 0. This it the variable `priors[\"own_states\"][\"p_k\"]` which is set to `[0.5, 0.5]` by default, i.e. agnostic. A more reasonable estimate for humans would favor the sophistication level 1. We can change it as follows:\n"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["init_states[\"own_states\"][\"p_k\"] = [0.3, 0.7]\n","tom_1.set_internal_states(init_states)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["opponent_states\n|   0-ToM\n|   |   opponent_states\n|   |   own_states\n|   |   |   p_op_mean0 (log odds):          0\n|   |   |   p_op_var0 (log scale):          0\n|   |   |   p_self (probability):           nan\n|   |   |   p_op (probability):             nan\nown_states\n|   p_k (probability):              [0.3, 0.7]\n|   p_op_mean (log odds):           [0]\n|   param_mean:                     [[0.0, 0.0, 0.0]]\n|   param_var (log scale):          [[0.0, 0.0, 0.0]]\n|   gradient:                       [[0.0, 0.0, 0.999999997998081]]\n|   p_self (probability):           nan\n|   p_op (probability):             nan\n"]}],"source":["# print the changed states\n","tom_1.print_internal()"]},{"source":["for an explanation of the internal states besides the  we recommend you examine "],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Help on method print_internal in module tomsup.agent:\n\nprint_internal(keys: Union[list, NoneType] = None, level: Union[list, NoneType] = None) method of tomsup.agent.TOM instance\n    keys (list | None): is the keys which you desire to print.\n    level (list | None):  list of integers containing levels to print\n    None indicate all levels will be printed.\n    \n    Explanation of internal states:\n    opponent_states: indicate that the following states belong to the\n    simulated opponent\n    own_states: indicate that the states belongs to the agent itself\n    p_k: is the estimated sophistication level of the opponent.\n    p_op_mean: The mean estimate of the opponents choice probability in\n    log odds.\n    param_mean: the mean estimate of opponent parameters (in the scale\n    used for the given parameter). If estimating another k-ToM the order\n    of estimates is 1) Volatility, 2) Behavioural temperature, 3) Dilution,\n    4) Bias. Note that bias is 3) if Dilution is not estimated.\n    param_var: the variance in log scale (same order as in param_mean)\n    gradient: the local-linear gradient for each estimate (same order as\n    in param_mean)\n    p_self: the probability of the agent itself choosing 1\n    p_op: the aggregate probability of the opponent choosing 1\n\n"]}],"source":["help(tom_1.print_internal)"]}],"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3},"version":"3.8.5-final"},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3,"kernelspec":{"name":"python37564bitea838f35b129458e9787f325adb7b1c3","display_name":"Python 3.7.5 64-bit","language":"python"}},"nbformat":4,"nbformat_minor":2}